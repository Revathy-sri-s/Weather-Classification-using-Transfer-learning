{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-17T17:52:22.691219Z","iopub.execute_input":"2023-05-17T17:52:22.691879Z","iopub.status.idle":"2023-05-17T17:52:22.722866Z","shell.execute_reply.started":"2023-05-17T17:52:22.691843Z","shell.execute_reply":"2023-05-17T17:52:22.721661Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:52:32.831330Z","iopub.execute_input":"2023-05-17T17:52:32.831743Z","iopub.status.idle":"2023-05-17T17:52:41.314233Z","shell.execute_reply.started":"2023-05-17T17:52:32.831709Z","shell.execute_reply":"2023-05-17T17:52:41.313096Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data_dir = \"/kaggle/input/animal-image-dataset-90-different-animals\"","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:52:58.982545Z","iopub.execute_input":"2023-05-17T17:52:58.983309Z","iopub.status.idle":"2023-05-17T17:52:58.988463Z","shell.execute_reply.started":"2023-05-17T17:52:58.983269Z","shell.execute_reply":"2023-05-17T17:52:58.987291Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"input_size = (224, 224)\ndatagen = ImageDataGenerator(rescale=1./255,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:53:30.281613Z","iopub.execute_input":"2023-05-17T17:53:30.281990Z","iopub.status.idle":"2023-05-17T17:53:30.287201Z","shell.execute_reply.started":"2023-05-17T17:53:30.281963Z","shell.execute_reply":"2023-05-17T17:53:30.286117Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = datagen.flow_from_directory(data_dir,target_size=input_size,batch_size=32,class_mode=\"categorical\",subset=\"training\")","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:53:53.232104Z","iopub.execute_input":"2023-05-17T17:53:53.232519Z","iopub.status.idle":"2023-05-17T17:53:54.881117Z","shell.execute_reply.started":"2023-05-17T17:53:53.232484Z","shell.execute_reply":"2023-05-17T17:53:54.880193Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 4320 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"val_data =datagen.flow_from_directory(data_dir,target_size=input_size,batch_size=32,class_mode=\"categorical\",subset=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:55:02.425985Z","iopub.execute_input":"2023-05-17T17:55:02.426431Z","iopub.status.idle":"2023-05-17T17:55:02.597105Z","shell.execute_reply.started":"2023-05-17T17:55:02.426395Z","shell.execute_reply":"2023-05-17T17:55:02.596109Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 1080 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"augmentation = ImageDataGenerator(rotation_range=20,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,fill_mode=\"nearest\")","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:55:20.947264Z","iopub.execute_input":"2023-05-17T17:55:20.947651Z","iopub.status.idle":"2023-05-17T17:55:20.953510Z","shell.execute_reply.started":"2023-05-17T17:55:20.947621Z","shell.execute_reply":"2023-05-17T17:55:20.952385Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_augmented = augmentation.flow_from_directory(data_dir,target_size=input_size,batch_size=32,class_mode=\"categorical\",subset=\"training\")","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:55:47.988483Z","iopub.execute_input":"2023-05-17T17:55:47.988875Z","iopub.status.idle":"2023-05-17T17:55:48.210848Z","shell.execute_reply.started":"2023-05-17T17:55:47.988845Z","shell.execute_reply":"2023-05-17T17:55:48.209919Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 5400 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:56:06.946801Z","iopub.execute_input":"2023-05-17T17:56:06.947179Z","iopub.status.idle":"2023-05-17T17:56:06.953963Z","shell.execute_reply.started":"2023-05-17T17:56:06.947150Z","shell.execute_reply":"2023-05-17T17:56:06.952894Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmodel = Sequential()\n# Add the firstconvolutional layer\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',\ninput_shape=(64, 64, 3)))\n# Add the first poolinglayer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add the second convolutionallayer\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n# Add the secondpooling layer\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add the flattenlayer\nmodel.add(Flatten())\n# Add the first hidden layer\nmodel.add(Dense(units=128,\nactivation='relu'))\n# Add the second hidden layer\nmodel.add(Dense(units=64,\nactivation='relu'))\n# Add the output layer\nmodel.add(Dense(units=90,\nactivation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:56:33.082119Z","iopub.execute_input":"2023-05-17T17:56:33.082527Z","iopub.status.idle":"2023-05-17T17:56:33.326398Z","shell.execute_reply.started":"2023-05-17T17:56:33.082496Z","shell.execute_reply":"2023-05-17T17:56:33.325308Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\nloss='categorical_crossentropy', metrics=['accuracy'])\n# Print the modelsummary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:56:54.435396Z","iopub.execute_input":"2023-05-17T17:56:54.435837Z","iopub.status.idle":"2023-05-17T17:56:54.483672Z","shell.execute_reply.started":"2023-05-17T17:56:54.435784Z","shell.execute_reply":"2023-05-17T17:56:54.482706Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 62, 62, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 12544)             0         \n                                                                 \n dense (Dense)               (None, 128)               1605760   \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dense_2 (Dense)             (None, 90)                5850      \n                                                                 \n=================================================================\nTotal params: 1,639,258\nTrainable params: 1,639,258\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data =ImageDataGenerator(rescale=1./255)\ntest_generator = test_data.flow_from_directory('/kaggle/input/animal-image-dataset-90-different-animals',target_size=(64, 64),batch_size=32,class_mode='categorical',shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:57:24.076241Z","iopub.execute_input":"2023-05-17T17:57:24.077182Z","iopub.status.idle":"2023-05-17T17:57:24.358064Z","shell.execute_reply.started":"2023-05-17T17:57:24.077145Z","shell.execute_reply":"2023-05-17T17:57:24.356984Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 5400 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator)\nprint('Test accuracy:',test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:57:41.968385Z","iopub.execute_input":"2023-05-17T17:57:41.969401Z","iopub.status.idle":"2023-05-17T17:59:04.820625Z","shell.execute_reply.started":"2023-05-17T17:57:41.969294Z","shell.execute_reply":"2023-05-17T17:59:04.819367Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"169/169 [==============================] - 69s 405ms/step - loss: 405.5648 - accuracy: 0.0000e+00\nTest accuracy: 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader, Dataset, Subset\nfrom torch.utils.data import random_split, SubsetRandomSampler\nfrom torchvision import datasets, transforms, models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom pytorch_lightning import LightningModule\nfrom pytorch_lightning import Trainer\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-05-17T17:59:32.032407Z","iopub.execute_input":"2023-05-17T17:59:32.032798Z","iopub.status.idle":"2023-05-17T17:59:39.146392Z","shell.execute_reply.started":"2023-05-17T17:59:32.032768Z","shell.execute_reply":"2023-05-17T17:59:39.145269Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"transform=transforms.Compose([transforms.RandomRotation(10), transforms.RandomHorizontalFlip(),transforms.Resize(224),transforms.CenterCrop(224),transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T18:00:15.390635Z","iopub.execute_input":"2023-05-17T18:00:15.391075Z","iopub.status.idle":"2023-05-17T18:00:15.398308Z","shell.execute_reply.started":"2023-05-17T18:00:15.391042Z","shell.execute_reply":"2023-05-17T18:00:15.396913Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"dataset0=datasets.ImageFolder(root=\"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\",transform=None)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T18:00:42.571542Z","iopub.execute_input":"2023-05-17T18:00:42.571943Z","iopub.status.idle":"2023-05-17T18:00:42.745659Z","shell.execute_reply.started":"2023-05-17T18:00:42.571912Z","shell.execute_reply":"2023-05-17T18:00:42.744798Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class_names=dataset0.classes\nprint(class_names)\nprint(len(class_names))\nclass DataModule(pl.LightningDataModule):\n\n    def __init__(self, transform=transform, batch_size=32):\n        super().__init__()\n        self.root_dir = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\"\n        self.transform = transform\n        self.batch_size = batch_size\n    def setup(self, stage=None):\n        dataset = datasets.ImageFolder(root=self.root_dir,transform=self.transform)\n        n_data = len(dataset)\n        n_train = int(0.8 * n_data)\n        n_test = n_data - n_train\n        train_dataset, test_dataset =torch.utils.data.random_split(dataset, [n_train, n_test])\n        self.train_dataset = DataLoader(train_dataset,\n        batch_size=self.batch_size, shuffle=True)\n        self.test_dataset = DataLoader(test_dataset,batch_size=self.batch_size)\n    def train_dataloader(self):\n        return self.train_dataset\n    def test_dataloader(self):\n        return self.test_dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T18:01:00.864489Z","iopub.execute_input":"2023-05-17T18:01:00.865668Z","iopub.status.idle":"2023-05-17T18:01:00.876063Z","shell.execute_reply.started":"2023-05-17T18:01:00.865630Z","shell.execute_reply":"2023-05-17T18:01:00.874994Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'flamingo', 'fly', 'fox', 'goat', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'mosquito', 'moth', 'mouse', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'wolf', 'wombat', 'woodpecker', 'zebra']\n90\n","output_type":"stream"}]},{"cell_type":"code","source":"class ConvolutionalNetwork(LightningModule):\n\n    def __init__(self):\n        super(ConvolutionalNetwork, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n        self.fc1 = nn.Linear(16 * 54 * 54, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 20)\n        self.fc4 = nn.Linear(20, len(class_names))\n    def forward(self, X):\n        X = F.relu(self.conv1(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = F.relu(self.conv2(X))\n        X = F.max_pool2d(X, 2, 2)\n        X = X.view(-1, 16 * 54 * 54)\n        X = F.relu(self.fc1(X))\n        X = F.relu(self.fc2(X))\n        X = F.relu(self.fc3(X))\n        X = self.fc4(X)\n        return F.log_softmax(X, dim=1)\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n        return optimizer\n    def training_step(self, train_batch, batch_idx):\n        X, y = train_batch\n        y_hat = self(X)\n        loss = F.cross_entropy(y_hat, y)\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n        self.log(\"train_loss\", loss)\n        self.log(\"train_acc\", acc)\n        return loss\n    def validation_step(self, val_batch, batch_idx):\n        X, y = val_batch\n        y_hat = self(X)\n        loss = F.cross_entropy(y_hat, y)\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n        self.log(\"val_loss\", loss)\n        self.log(\"val_acc\", acc)\n    def test_step(self, test_batch, batch_idx):\n        X, y = test_batch\n        y_hat = self(X)\n        loss = F.cross_entropy(y_hat, y)\n        pred = y_hat.argmax(dim=1, keepdim=True)\n        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n        self.log(\"test_loss\", loss)\n        self.log(\"test_acc\", acc)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T18:02:06.026826Z","iopub.execute_input":"2023-05-17T18:02:06.027232Z","iopub.status.idle":"2023-05-17T18:02:06.045490Z","shell.execute_reply.started":"2023-05-17T18:02:06.027203Z","shell.execute_reply":"2023-05-17T18:02:06.044325Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"datamodule = DataModule()\ndatamodule.setup()\ntrain_loader = datamodule.train_dataloader()\nfor imgs,labels in train_loader:\n   break\nprint(labels)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T18:02:32.308171Z","iopub.execute_input":"2023-05-17T18:02:32.308623Z","iopub.status.idle":"2023-05-17T18:02:32.840945Z","shell.execute_reply.started":"2023-05-17T18:02:32.308560Z","shell.execute_reply":"2023-05-17T18:02:32.839882Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tensor([15, 63, 88, 39, 69, 39,  5, 70, 71, 16, 59, 69, 84, 27, 74, 82,  9, 79,\n        39, 20, 51,  6, 35, 69, 36, 31, 83, 36, 42, 35, 12,  9])\n","output_type":"stream"}]},{"cell_type":"code","source":"if __name__ == '__main__':\n datamodule = DataModule()\n datamodule.setup()\n model = ConvolutionalNetwork()\n trainer = pl.Trainer(max_epochs=10)\n trainer.fit(model, datamodule)\n datamodule.setup(stage='test')\n test_loader = datamodule.test_dataloader()\n trainer.test(dataloaders=test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T18:02:54.209335Z","iopub.execute_input":"2023-05-17T18:02:54.209705Z","iopub.status.idle":"2023-05-17T18:22:38.382207Z","shell.execute_reply.started":"2023-05-17T18:02:54.209676Z","shell.execute_reply":"2023-05-17T18:22:38.381176Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e2ace98337d41309d69cc583773a4c9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n  rank_zero_warn(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2303e09d4ab545d4905d500304da6609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.22962963581085205   \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.092629909515381    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.22962963581085205    </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.092629909515381     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}}]}]}